---
title: "AM10 Group Project 1"
author: "Group 1: Alex Scheuer, Dhruvi Mundra, Heng Jian Shun, Marta Wnek, Sharon Wenyu Xu, Xueying Liu"
date: "`r Sys.Date()`"
output: html_document
output:
  html_document:
    theme: flatly
    highlight: zenburn
    number_sections: yes
    toc: yes
    toc_float: yes
    code_folding: show
---

```{r, setup, echo=FALSE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
options(digits = 3)

# default figure size
knitr::opts_chunk$set(
  fig.width=6.75, 
  fig.height=6.75,
  fig.align = "center"
)
```

```{r, load_libraries, include = FALSE}
library(tidyverse) # the usual stuff: dplyr, readr, and other goodies
library(lubridate) # to handle dates
library(GGally) # for correlation-scatter plot matrix
library(ggfortify) # to produce residual diagnostic plots
library(janitor) # clean_names()
library(broom) # use broom:augment() to get tidy table with 
library(extrafont)
library(vroom)
library(ggtext)
library(gapminder)
library(ggrepel)
library(patchwork)
library(gghighlight)
library(skimr)

library(rsample) # to split dataframe in training- & testing sets
library(huxtable) # to get summary table of all models produced
library(caret) # to train more advanced models (k-fold cross-validation, stepwise regression, LASSO)
library(nnet) # to calculate the maximum value of a vector
library(pROC) # to plot ROC curves
library(MLmetrics) #for caret LASSO logistic regression
library(DescTools)
library(sampling)
library(gbm)
library(randomForest)
```

# Introduction

## Load the data

Dataset source: <https://www.kaggle.com/datasets/hernan4444/anime-recommendation-database-2020>

```{r, load_data, warning=FALSE, message=FALSE}
animeinfo_raw <- read_csv(here::here("anime.csv")) %>%
  clean_names() # use janitor::clean_names()

# animerating_raw <- read_csv(here::here("animelist.csv")) %>%
#   clean_names() # use janitor::clean_names()
```

# ICE the data: Inspect, Clean, Explore

Any data science engagement starts with ICE. Inspecting, Clean and Explore the data.

## Inspect the data

Inspect the data to understand what different variables mean. Variable definitions can be found in the excel version of the data.

### Anime List data

```{r, Inspect anime list data}
glimpse(animeinfo_raw)
skimr::skim(animeinfo_raw)

# Check through each factor columns and inspect number of unique factors.
unique(animelist$type)
unique(animelist$source)
unique(animelist$rating)
# These columns are fine - There are distinct categories for each

```

### Anime Ratings data

```{r, Inspect anime ratings data}
glimpse(animerating_raw)
skimr::skim(animerating_raw)

```

## Clean the data

-   Clean names

-   Remove redundant columns

-   Remove rows that contain cells with missing values for score since that is the most important one

-   Change variable types where needed

-   Isolate date in which anime started airing

-   Create indicator variables for year, month, week, day for "aired from"

-   Re-calculate duration of anime as minutes

-   Extract date premiered in terms of year and season

-   Extract multi-value columns (genres, licensors, producers, studios) and create binary columns for each

### Clean Anime List data

```{r, clean anime list data, warning=FALSE}
animelist_intermediate <- animeinfo_raw %>%
  select(-c(english_name, japanese_name)) %>% #drop redundant columns 
  dplyr::mutate(across(c(score, episodes, ranked), as.numeric)) %>% #convert to numeric
  dplyr::mutate(across(score_10:score_1, as.numeric)) %>% #convert to numeric
  drop_na(score) %>% #drop rows with "Unknown" scores
  
  dplyr::mutate(aired_from = str_split(aired, "to", simplify = T)[, 1]) %>% 
  mutate(
    aired_from = mdy(aired_from),
    aired_from_year = year(aired_from),
    aired_from_month = month(aired_from),
    aired_from_week = week(aired_from),
    aired_from_day = day(aired_from)
    ) %>% #cleaned aired_from
  select(-c(aired)) %>% #drop aired 
  
  mutate(
    duration_hour = str_extract(duration, "(\\d)+(?= hr)"),
    duration_hour = ifelse(is.na(duration_hour), 0, as.numeric(duration_hour)),
    duration_min = as.numeric(str_extract(duration, "(\\d)+(?= min)")),
    duration = (duration_hour * 60) + duration_min #cleaned duration - number of minutes
    ) %>%
  select(-c(duration_hour, duration_min)) %>% #drop duration_hour and duration_min
  
  mutate(
    premier_season = str_extract(premiered, "\\D+"),
    premier_year = as.numeric(str_extract(premiered, "\\d+"))) %>% 
  select(-c(premiered)) #drop premiered
  
glimpse(animelist_intermediate)
  

########################
# Replace (creating binary columns) and remove multi-valued columns (genres, licensors, producers, studios)
animelist_clean <- animelist_intermediate %>% 
  mutate(genre = strsplit(genres, ", ")) %>%
  unnest(genre) %>% 
  arrange(genre) %>%  
  pivot_wider(names_from = genre,
              names_prefix = "genre_", names_repair = "universal",
              values_from = genre, values_fill = 0, values_fn = length) %>% #binary genres
  
  mutate(licensor = strsplit(licensors, ", ")) %>%
  unnest(licensor) %>% 
  arrange(licensor) %>%  
  pivot_wider(names_from = licensor,
              names_prefix = "licensor_", names_repair = "universal",
              values_from = licensor, values_fill = 0, values_fn = length) %>% #binary licensors
  
  mutate(producer = strsplit(producers, ", ")) %>%
  unnest(producer) %>% 
  arrange(producer) %>%  
  pivot_wider(names_from = producer,
              names_prefix = "producer_", names_repair = "universal",
              values_from = producer, values_fill = 0, values_fn = length) %>% #binary producers
  
  mutate(studio = strsplit(studios, ", ")) %>%
  unnest(studio) %>% 
  arrange(studio) %>%  
  pivot_wider(names_from = studio,
              names_prefix = "studio_", names_repair = "universal",
              values_from = studio, values_fill = 0, values_fn = length) %>% #binary studios
  clean_names() %>% 
  select(-c(genres, licensors, producers, studios)) %>%  #drop multivalue columns
  arrange(mal_id) #arrange by anime id for ease
  

rm(animelist_intermediate)
```

### Clean Anime Ratings data

```{r, clean anime ratings data, warning=FALSE}
# Store all unique anime IDs as list
uniqueid <- unique(animelist_clean$mal_id)

# rating_clean <- animerating_raw %>% 
#   filter(anime_id %in% uniqueid)

```

## Explore


```{r}
watchtime_by_genre <- animelist_clean_long %>%
  dplyr::group_by(genre) %>% 
  dplyr::mutate(watch_time = sum(duration)) %>%
  ungroup()
  arrange(genre)
  select(genre, duration, episodes, completed) %>% 
  distinct(genre, .keep_all = TRUE) 
  ungroup() %>% 
  slice_max(watch_time, n = 20) %>% 
  group_by_gen
  
  
  
  group_by(genre, type) %>% 
  summarise(watch_time = mean(duration*episodes*completed)) %>% 
  # group_by(genre) %>% 
  # mutate(genre = fct_reorder(genre, watch_time)) %>% 
  # ungroup() %>% 
  # group_by_(genre, type) %>% 
  ungroup() %>% 
  slice_max(watch_time, n = 20) %>%
  mutate(genre = str_replace(genre, "_", " ")) %>%
  mutate(genre = str_to_title(genre))
plot3 <- ggplot(data = watchtime_by_genre, aes(x = watch_time, y = fct_reorder(genre, watch_time), fill = type)) +
  geom_col() +
  labs(
    title = "20 most watched Anime genres by type",
    x = "Watchtime of animes") +
  theme_classic(base_family = "Times New Roman") +
  theme(plot.title.position = "plot",
        plot.title = element_textbox_simple(size = 14),
        axis.title.y = element_blank(),
        ) +
  scale_fill_manual(values = c('#0056a7', '#126cb6', '#2681c5', '#3a97d3', '#52ace0', '#6dc2ec', '#8bd7f5', '#aeecfc', '#d6ffff'))
plot(plot3)


```













### Exploring genre counts

```{r create long animelist}
# Create long data on genre
animelist_clean_long <- animelist_clean %>% 
  pivot_longer(cols = c(genre_action : genre_yuri), names_to = "genre", values_to = "binary") %>% 
  relocate(genre, .before = score) %>% 
  filter(binary == 1) %>% 
  select(c(mal_id : premier_year)) %>% 
  mutate(id = row_number())%>% 
  relocate(id, .before = mal_id) %>%
  mutate(genre = str_extract(genre, '(?<=_).+')) %>% 
  filter(genre != "unknown") #Remove unknown genres

  
  
```

```{r some basic genre count plots}
count_by_genre <- animelist_clean_long %>% 
  group_by(genre) %>% 
  summarise(count = n()) %>% 
  # slice_max(count, n = 20) %>%
  mutate(genre = str_replace(genre, "_", " ")) %>% 
  mutate(genre = str_to_title(genre)) %>% 
  arrange(count)

ggplot(data = count_by_genre, aes(x = count, y = fct_reorder(genre, count))) +
  geom_col() +
  labs(
    title = "<b>Top 20 Anime Genres</b>",
    x = "Number of animes") +
  theme_minimal() +
  theme(plot.title.position = "plot",
        plot.title = element_textbox_simple(size = 14),
        axis.title.y = element_blank(),
        legend.position = "none"
        )
```

## Machine Learning Techniques

### User recommendation

### Predicting Anime drop rates

```{r predicting drops}
#split the data in testing and training.

animelist_dropped <- animelist_clean %>% 
  relocate(dropped, .before = mal_id) %>% 
  select(dropped, c(score : plan_to_watch), c(aired_from_year : premier_year), c(genre_action : genre_yuri)) %>% 
  select(-c(premier_season, premier_year)) %>%  #Dropped premier beccause there are too many NAs/Unknowns
  drop_na(.) %>% #Drop na values for analysis
  filter(source != "Unknown") %>% 
  filter(rating != "Unknown") %>% 
  # levels(droplevels(animelist_dropped$source)) %>% 
  select(-c(source)) %>%  #Drop source for convenience
  select(-c(ranked, popularity)) #Drop ranked, popularity

skim(animelist_dropped)


unknown_count <- as.data.frame(sapply(animelist_dropped, function(x) sum(x == "Unknown"))) %>% 
  rownames_to_column(., "name")
NA_count <- as.data.frame(sapply(animelist_dropped, function(x) sum(is.na(x))))
unknown_NA_count <- cbind(unknown_count, NA_count) %>% 
  # lapply(., function(x) as.numeric(x)) %>%
  # as.data.frame(.) %>% 
  mutate_all(~replace(., is.na(.), 0))
colnames(unknown_NA_count) <- c("name", "unknown", "NA")

overall_invalid_count <- unknown_NA_count %>% 
  mutate(overall = unknown + `NA`)

set.seed(1234)
train_test_split <- initial_split(animelist_dropped, prop = 0.7)
training <- training(train_test_split)
testing <- testing(train_test_split)


# we will look for the optimal lambda in this sequence (we will try 1000 different lambdas, feel free to try more if necessary)
lambda_seq <- seq(0, 0.01, length = 1000)


#the method "cv" stands for cross validation. We re going to create 10 folds.  
control <- trainControl (
    method="cv",
    number=10,
    verboseIter=TRUE) #by setting this to true the model will report its progress after each estimation


model_lm<-lm(dropped~., training)
predictions <- predict(model_lm,testing)


# lasso regression using k-fold cross validation to select the best lambda
lasso <- train(
 dropped ~ .,
 data = training,
 method = "glmnet",
  preProc = c("center", "scale"), #This option standardizes the data before running the LASSO regression
  trControl = control,
  tuneGrid = expand.grid(alpha = 1, lambda = lambda_seq) #alpha=1 specifies to run a LASSO regression.
  )

# Model coefficients
coef(lasso$finalModel, lasso$bestTune$lambda)
nonzerocoef<-data.frame(as.matrix(coef(lasso$finalModel, lasso$bestTune$lambda)))


# Best lambda
lasso$bestTune$lambda

# Count of how many coefficients are greater than zero and how many are equal to zero

sum(coef(lasso$finalModel, lasso$bestTune$lambda)!=0)
sum(coef(lasso$finalModel, lasso$bestTune$lambda)==0)

# Make predictions
predictions <- predict(lasso,testing)
a <- cbind(testing, predictions) %>% 
  select(c(dropped, predictions))

ggplot(a)+
  geom_point(aes(x = dropped, y = predictions))

# Model prediction performance

data.frame(
  RMSE = RMSE(predictions, testing$dropped),
  Rsquare = R2(predictions, testing$dropped)
)





```

### Clustering and PCA

```{r, prepare data for clustering}
#### focus only on tasting points and so ignore geographical coordinates
animelist_clean_genres<- animelist_clean %>% select(genre_action : genre_yuri)
#### scale data: By scaling we substract the average value of a column from each observation and divide each observation by the standard deviation of the column it belongs to
animelist_clean_genres<-data.frame(scale(animelist_clean_genres))
```

```{r kmeans-elbow, message=FALSE, warning=FALSE}
library(purrr) #a package for writing succinctfor loops

# Use map_dbl to run K-Means models with varying value of k 
tot_withinss <- map_dbl(1:10,  function(k){
  model <- kmeans(x = animelist_clean_genres, centers = k,iter.max = 100, nstart = 10)
  model$tot.withinss
})

# Generate a data frame containing both k and tot_withinss
elbow_df <- data.frame(
  k = 1:10 ,
  tot_withinss = tot_withinss
)

# Plot the elbow plot
ggplot(elbow_df, aes(x = k, y = tot_withinss)) +
  geom_line() +
  scale_x_continuous(breaks = 1:10)

#Here is a short way of producing the elbow chart using "fviz_nbclust" function. 
fviz_nbclust(animelist_clean_genres,kmeans, method = "wss")+
  labs(subtitle = "Elbow method")
```

```{r kmeans-PCA number of clusters, message=FALSE, warning=FALSE}
# eclust function (part of factoextra) makes it easier to visuliaze clustering results
model_km2 <- eclust(animelist_clean_genres, "kmeans", k = 2,nstart = 50, graph = FALSE)
model_km2$size
model_km3 <- eclust(animelist_clean_genres, "kmeans", k = 3,nstart = 50, graph = FALSE)
model_km3$size
model_km4 <- eclust(animelist_clean_genres, "kmeans", k = 4,nstart = 50, graph = FALSE)
model_km4$size
model_km5 <- eclust(animelist_clean_genres, "kmeans", k = 5,nstart = 50, graph = FALSE)
model_km5$size


# plots to compare
#I use the fviz_cluster function which is part of the`factoextra` library
p1 <- fviz_cluster(model_km2, geom = "point", data = animelist_clean_genres) + ggtitle("k = 2")
p2 <- fviz_cluster(model_km3, geom = "point",  data = animelist_clean_genres) + ggtitle("k = 3")
p3 <- fviz_cluster(model_km4, geom = "point",  data = animelist_clean_genres) + ggtitle("k = 4")
p4 <- fviz_cluster(model_km5, geom = "point",  data = animelist_clean_genres) + ggtitle("k = 5")

library(gridExtra)
grid.arrange(p1, p2, p3, p4, nrow = 2)
```

```{r centre plots for k = 1:5}
#Plot centers

#Plot centers for k=2
xa<-data.frame(cluster=as.factor(c(1:2)),model_km2$centers)
xak2<-xa %>% gather(variable,value,-cluster,factor_key = TRUE)

graphknn2<-ggplot(xak2, aes(x = variable, y = value))+  geom_line(aes(color =cluster,group = cluster), linetype = "dashed",size=1)+ geom_point(size=1,shape=4)+geom_hline(yintercept=0)+theme(text = element_text(size=10),
        axis.text.x = element_text(angle=45, hjust=1),legend.title=element_text(size=5),legend.text = element_text(size=5))+ggtitle("K-means Centers k=2")

#Plot centers for k=3
xa<-data.frame(cluster=as.factor(c(1:3)),model_km3$centers)
xa3<-xa %>% gather(variable,value,-cluster,factor_key = TRUE)

graphknn3<-ggplot(xa3, aes(x = variable, y = value))+  geom_line(aes(color =cluster,group = cluster), linetype = "dashed",size=1)+ geom_point(size=1,shape=4)+geom_hline(yintercept=0)+theme(text = element_text(size=10),
        axis.text.x = element_text(angle=45, hjust=1),legend.title=element_text(size=5),legend.text = element_text(size=5))+ggtitle("K-means Centers k=3")

#Plot centers for k=4
xa<-data.frame(cluster=as.factor(c(1:4)),model_km4$centers)

xa4<-xa %>% gather(variable,value,-cluster,factor_key = TRUE)
graphknn4<-ggplot(xa4, aes(x = variable, y = value))+  geom_line(aes(color = cluster,group = cluster), linetype = "dashed",size=1)+ geom_point(size=1,shape=4)+geom_hline(yintercept=0)+theme(text = element_text(size=10),
        axis.text.x = element_text(angle=45, hjust=1),legend.title=element_text(size=5),legend.text = element_text(size=5))+ggtitle("K-means Centers k=4")

#Plot centers for k=5
xa<-data.frame(cluster=as.factor(c(1:5)),model_km5$centers)

xa5<-xa %>% gather(variable,value,-cluster,factor_key = TRUE)
graphknn5<-ggplot(xa5, aes(x = variable, y = value))+  geom_line(aes(color = cluster,group = cluster), linetype = "dashed",size=1)+ geom_point(size=1,shape=4)+geom_hline(yintercept=0)+theme(text = element_text(size=10),
        axis.text.x = element_text(angle=45, hjust=1),legend.title=element_text(size=5),legend.text = element_text(size=5))+ggtitle("K-means Centers k=5")
  
model_km2$size
model_km3$size
model_km4$size
model_km5$size


grid.arrange(graphknn2, graphknn3,graphknn4,graphknn5, nrow = 2)
```

```{r silhouette plots}
s2<-fviz_silhouette(model_km2)+ ggtitle(paste("k = 2", "avg sw=",format(round(model_km2$silinfo$avg.width,3))))
s3<-fviz_silhouette(model_km3)+ ggtitle(paste("k = 3", "avg sw=",format(round(model_km3$silinfo$avg.width,3))))
s4<-fviz_silhouette(model_km4)+ ggtitle(paste("k = 4", "avg sw=",format(round(model_km4$silinfo$avg.width,3))))
s5<-fviz_silhouette(model_km5)+ ggtitle(paste("k = 5", "avg sw=",format(round(model_km5$silinfo$avg.width,3))))
grid.arrange(s2, s3,s4,s5, nrow = 2)

```
